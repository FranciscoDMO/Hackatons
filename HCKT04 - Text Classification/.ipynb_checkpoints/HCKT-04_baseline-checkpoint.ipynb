{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84845fd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "trailing comma not allowed without surrounding parentheses (4035637606.py, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [1]\u001b[0;36m\u001b[0m\n\u001b[0;31m    from sklearn.model_selection import train_test_split,\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m trailing comma not allowed without surrounding parentheses\n"
     ]
    }
   ],
   "source": [
    "# importing needed packages here\n",
    "\n",
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from spacy.matcher import Matcher\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split, \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432a918a",
   "metadata": {},
   "source": [
    "# Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc23b4d9",
   "metadata": {},
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d18d37",
   "metadata": {},
   "source": [
    "# Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291ec8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the required data\n",
    "data_path = \"\"\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65609e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55548ea2",
   "metadata": {},
   "source": [
    "# Loading spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7554fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# here upload stopwords from nltk but it can be from spacy\n",
    "# you can also add or remove stopwords\n",
    "# Adding single token as stopword ‚Üí nlp.Defaults.stop_words.add(‚Äúperfect‚Äù)\n",
    "# Adding multiple tokens ‚Üí nlp.Defaults.stop_words|={‚Äúhot‚Äù,‚Äùcobb‚Äù}\n",
    "\n",
    "# Removing single token ‚Üínlp.Defaults.stop_words.remove(‚Äúwhat‚Äù)\n",
    "# Removing multiple tokens ‚Üí nlp.Defaults.stop_words -= {‚Äúwho‚Äù, ‚Äúwhen‚Äù}\n",
    "\n",
    "en_stopwords = nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b9d699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As in the exercise notebook BLU09 to merge the text together as a list\n",
    "\n",
    "#nlp.add_pipe(\"merge_entities\", after=\"ner\")\n",
    "\n",
    "# Let's get the text of the news article processed by SpaCy - This might take a while depending on \n",
    "#   your hardware (a break to walk the dog? üê∂)\n",
    "\n",
    "#docs = list(tqdm(nlp.pipe(df[\"text\"], batch_size=20, n_process=cpu_count-1), total=len(df[\"text\"])))\n",
    "#docs[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c17b7f",
   "metadata": {},
   "source": [
    "# Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f051e057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    \"\"\"\n",
    "    Hint: Remember the good old RegEx from 2 LUs ago\n",
    "        how can I just remove everything except words, digits and spaces?\n",
    "    \"\"\"\n",
    "    \n",
    "    # text = re.sub(...)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    text = re.sub(r\"[^\\w\\d\\s]+\", \"\", text)\n",
    "\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "def remove_stopwords(text, stopwords):\n",
    "    \"\"\"\n",
    "    Hint: You may want to split the text into tokens using the tokenizer, it might help when searching for stopwords\n",
    "        If you do, do not forget to join the tokens afterwards!\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    tokenizer = WordPunctTokenizer()\n",
    "    BoW = [words for words in tokenizer.tokenize(text) if words not in stopwords]\n",
    "    text_processed = \" \".join(BoW)\n",
    "    \n",
    "    # Return the full string again here\n",
    "    return text_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185f3956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(df, column):\n",
    "    \n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    df_processed[column] = df_processed[column].apply(remove_punctuation)\n",
    "    \n",
    "    \n",
    "    df_processed[column] = df_processed[column].apply(remove_stopwords, stopwords = en_stopwords)\n",
    "    \n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c2fbfa",
   "metadata": {},
   "source": [
    "# Establishing a baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa040ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_split(df_processed, text=None, label=None):\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test = train_test_split(df_processed[text], df_processed[label], \n",
    "                                                    test_size=0.2, random_state=42, stratify=df_processed[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec69621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_with_tfidf(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Train a Random Forest using sklearn's Pipeline and return the trained model and its accuracy in the test set.\n",
    "    \"\"\"\n",
    "    \n",
    "    # pipe = (...)\n",
    "    # pipe.fit(...)\n",
    "    # (...)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    # important: only train the vectorizer on the training data (but with pipeline no problems with it)\n",
    "    # we can use for classifier: MultinomialNB(), SVC(), GradientBoostingClassifier()\n",
    "    pipe = Pipeline([(\"Tfidf\", TfidfVectorizer()), # ngram_range(1,2) can be added\n",
    "                    (\"classifier\", RandomForestClassifier())])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = pipe.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)\n",
    "    acc = round(accuracy_score(y_test, y_pred),3)\n",
    "    f1 = round(f1_score(y_true, y_pred, average='weighted'),3) # use \"weighted\" for umbalanced data otherwise use =\"macro\"\n",
    "    precision = round(precision_score(y_true, y_pred, average='weighted'),3)\n",
    "    recall = round(recall_score(y_true, y_pred, average='weighted'),3)\n",
    "    \n",
    "    return pipe, y_pred, y_prob, acc, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f01566",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe, y_pred, y_prob, acc, f1, precision, recall = baseline_with_tfidf(train_split(preprocess_text(df, column), text=df[\"\"], label=df[\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e82a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "#In this matrix, the first row represents the negative class and the second row represents the positive class.\n",
    "# The first column represents the instances that were predicted to be negative \n",
    "# and the second column represents the instances that were predicted to be positive.\n",
    "\n",
    "labels = ['Negative', 'Positive'] # be careful with the order of the label\n",
    "ax = sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "ax.set_xlabel(\"Predicted Labels\")\n",
    "ax.set_ylabel(\"True Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c550e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm_roc_curve(y_test, y_pred, acc, precision, recall, f1):\n",
    "    print(f'Accuracy of the model: {np.round(acc*100,2)}%')\n",
    "    print(f'Precision Score of the model: {np.round(precision*100,2)}%')\n",
    "    print(f'Recall Score of the model: {np.round(recall*100,2)}%')\n",
    "    print(f'F1 Score of the model: {np.round(f1*100,2)}%')\n",
    "    print('-'*50)\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize = (25,  8))\n",
    "    ax1 = plot_confusion_matrix(y_test, y_pred, ax= ax[0], cmap= 'YlGnBu')\n",
    "    ax2 = plot_roc(y_test, y_prob, ax= ax[1], plot_macro= False, plot_micro= False, cmap= 'summer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2534102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_roc_curve(y_test, y_pred, acc, precision, recall, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a92edf",
   "metadata": {},
   "source": [
    "# Data visualization and Features engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e79b55b",
   "metadata": {},
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c597e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[label_column].value_counts().plot(kind='bar')\n",
    "\n",
    "# add a title and labels to the plot\n",
    "plt.title('Count of label column')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f65bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b30f02",
   "metadata": {},
   "source": [
    "### Wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7980a6b0",
   "metadata": {},
   "source": [
    " To change the column name in this code and maybe remore the stopwords (look at wordcloud function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60751eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add stopwords= parameters in the wordcloud\n",
    "\n",
    "def nonan(x):\n",
    "    if type(x) == str:\n",
    "        return x.replace(\"\\n\", \"\")\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "text = ' '.join([nonan(abstract) for abstract in df[\"comment_text\"]])\n",
    "wordcloud = WordCloud(max_font_size=None, background_color='black', collocations=False,\n",
    "                      width=1200, height=1000).generate(text)\n",
    "fig = px.imshow(wordcloud)\n",
    "fig.update_layout(title_text='Common words in comments')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ae6ff0",
   "metadata": {},
   "source": [
    "## Features engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd292ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating the column text_len\n",
    "df['text_len']=df_train['text'].apply(lambda x:len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8897fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The below function comes in handy to count the number of characters in a text\n",
    "def char_count(text):\n",
    "    charc=0\n",
    "    for char in text.split():\n",
    "        charc +=len(char)\n",
    "    return charc\n",
    "\n",
    "#Generating the column text_char_len\n",
    "df'text_char_len']=df['text'].apply(char_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1da8e2",
   "metadata": {},
   "source": [
    "# Feature Union and pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b521b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Selector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a column from the dataframe to perform additional transformations on\n",
    "    \"\"\" \n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "\n",
    "class TextSelector(Selector):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on text columns in the data\n",
    "    \"\"\"\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "    \n",
    "class NumberSelector(Selector):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0538991",
   "metadata": {},
   "source": [
    "## The following pipeline and Feature union need to be changed acording to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e79344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipe = Pipeline([(\"selector\", TextSelector(key=\"text\")),\n",
    "                      (\"tfidf\", TfidfVectorizer())])\n",
    "\n",
    "nb_adj_adv_pipe = Pipeline([(\"selector\", NumberSelector(key=\"nb_adj_adv\")),\n",
    "                            (\"standard\", StandardScaler())])\n",
    "\n",
    "nb_words_pipe = Pipeline([(\"selector\", NumberSelector(key=\"nb_words\")),\n",
    "                          (\"standard\", StandardScaler())])\n",
    "\n",
    "doc_length_pipe = Pipeline([(\"selector\", NumberSelector(key=\"doc_length\")),\n",
    "                            (\"standard\", StandardScaler())])\n",
    "\n",
    "avg_word_length_pipe = Pipeline([(\"selector\", NumberSelector(key=\"avg_word_length\")),\n",
    "                                 (\"standard\", StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb08cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = FeatureUnion([(\"text\", text_pipe), \n",
    "                      (\"nb_adj_adv\", nb_adj_adv_pipe),\n",
    "                     (\"nb_words\", nb_words_pipe),\n",
    "                     (\"doc_length\", doc_length_pipe),\n",
    "                     (\"avg_word_length\", avg_word_length_pipe)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9f84a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def improved_pipeline(feats, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Train a Random Forest using sklearn's Pipeline and return the trained model and its accuracy in the test set.\n",
    "    Don't forget to add the feats to the Pipeline!\n",
    "    \"\"\"\n",
    "    \n",
    "    # pipe = (...)\n",
    "    # pipe.fit(...)\n",
    "    # (...)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    # important: only train the vectorizer on the training data (but with pipeline no problems with it)\n",
    "    # we can use for classifier: MultinomialNB(), BernoulliNB(), SVC(), GradientBoostingClassifier(), \n",
    "    # LogisticRegression()\n",
    "    pipe = Pipeline([('feats', feats),\n",
    "                     ('clf', RandomForestClassifier())])\n",
    "    \n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = pipe.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted') # use \"weighted\" for umbalanced data otherwise use =\"macro\"\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    return pipe, y_pred, y_prob, acc, f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b53bfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe, pipe, y_pred, y_prob, acc, f1, precision, recall = improved_pipeline(feats, train_split(preprocess_text(df, column), text=df[\"\"], label=df[\"\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b053a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "#In this matrix, the first row represents the negative class and the second row represents the positive class.\n",
    "# The first column represents the instances that were predicted to be negative \n",
    "# and the second column represents the instances that were predicted to be positive.\n",
    "\n",
    "labels = ['Negative', 'Positive'] # be careful with the order of the label\n",
    "ax = sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "ax.set_xlabel(\"Predicted Labels\")\n",
    "ax.set_ylabel(\"True Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeab30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_roc_curve(y_test, y_pred, acc, precision, recall, f1)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
